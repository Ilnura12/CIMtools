# -*- coding: utf-8 -*-
#
#  Copyright 2019 Assima Rakhimbekova <asima.astana@outlook.com>
#  This file is part of CIMtools.
#
#  CIMtools is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, see <https://www.gnu.org/licenses/>.
#
from .domain_selection.threshold_functions import function
from numpy import array, column_stack, eye, linalg, ones, sqrt, unique
from sklearn.base import BaseEstimator
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.utils import safe_indexing
from sklearn.utils.validation import check_array, check_is_fitted


class Leverage(BaseEstimator):
    """ Distance-based method
    The model space can be represented by a two-dimensional matrix comprising n chemicals (rows) and
    k variables (columns), called the descriptor matrix (X). The leverage of a chemical provides a measure of the
    distance of the chemical from the centroid of X. Chemicals close to the centroid are less influential in model
    building than are extreme points. The leverages of all chemicals in the data set are generated by manipulating X
    according to Equation 1, to give the so-called Influence Matrix or Hat Matrix (H).

    H = X(XTX)–1 XT (Equation 1)

    where X is the descriptor matrix, XT is the transpose of X, and (A)–1 is the inverse of matrix A, where A = (XTX).

    The leverages or hat values (hi) of the chemicals (i) in the descriptor space are the diagonal elements of H,
    and can be computed by Equation 2.

    hii = xiT(XTX)–1 xi (Equation 2)

    where xi is the descriptor row-vector of the query chemical.
    A “warning leverage” (h*) is generally (!) fixed at 3p/n, where n is the number of training chemicals, and p
    the number of model variables plus one.

    A “warning leverage” can be found on internal cross-validation.

    A chemical with high leverage in the training set greatly influences
    the regression line: the fitted regression line is forced near to the observed value and its residual
    (observed-predicted value) is small, so the chemical does not appear to be an outlier, even though it may actually
    be outside the AD. In contrast, if a chemical in the test set has a hat value greater than the warning leverage h*,
    this means that the prediction is the result of substantial extrapolation and therefore may not be reliable.
    """
    def __init__(self, warning_leverage='auto', score='ba', reg_model=RandomForestRegressor(n_estimators=500, random_state=1)):
        self.warning_leverage = warning_leverage
        self.score = score
        self.reg_model = reg_model

    def __make_inverse_matrix(self, X):
        X = column_stack(((ones(X.shape[0])), X))
        influence_matrix = X.T.dot(X) + eye(X.shape[1]).dot(1e-8)
        return linalg.inv(influence_matrix)

    def __find_leverages(self, X, inverse_influence_matrix):
        X = column_stack(((ones(X.shape[0])), X))
        return array([X[i, :].dot(inverse_influence_matrix).dot(X[i, :]) for i in range(X.shape[0])])

    def fit(self, X, y=None):
        """Learning is to find the inverse matrix for X and calculate the threshold.

        Parameters
        ----------
        X : array-like or sparse matrix, shape (n_samples, n_features)
            The input samples. Use ``dtype=np.float32`` for maximum
            efficiency.
        y : array-like, shape = [n_samples] or [n_samples, n_outputs]
            The target values (real numbers in regression).

        Returns
        -------
        self : object
        """
        # Check that X have correct shape
        X = check_array(X)
        if y is not None:
            y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)
        self.inverse_influence_matrix = self.__make_inverse_matrix(X)
        if self.warning_leverage == 'auto':
            self.threshold_value = 3 * (1 + X.shape[1]) / X.shape[0]
        elif self.warning_leverage == 'cv':
            self.threshold_value = {'z': 0, 'score': 0}
            Y_pred, Y_true, AD = [], [], []
            cv = KFold(n_splits=5, random_state=1, shuffle=True)
            for train_index, test_index in cv.split(X):
                x_train = safe_indexing(X, train_index)
                x_test = safe_indexing(X, test_index)
                y_train = safe_indexing(y, train_index)
                y_test = safe_indexing(y, test_index)
                self.reg_model.fit(x_train, y_train)
                y_pred = self.reg_model.predict(x_test)
                if self.score == 'ba':
                    y_pred = abs(y_test - y_pred) <= 3 * sqrt(mean_squared_error(y_test, y_pred))
                Y_pred.extend(y_pred)
                Y_true.extend(y_test)
                ad_model = self.__make_inverse_matrix(x_train)
                AD.extend(self.__find_leverages(x_test, ad_model))
            AD_ = unique(AD)
            for z in AD_:
                AD_new = AD <= z
                val = function(metric=self.score, Y_true=array(Y_true), Y_pred=array(Y_pred), AD=AD_new)
                if val >= self.threshold_value['score']:
                    self.threshold_value['score'] = val
                    self.threshold_value['z'] = z
        return self

    def predict_proba(self, X):
        """Predict the distances for X to center of the training set.

        Parameters
        ----------
        X : array-like or sparse matrix, shape (n_samples, n_features)
            The input samples. Internally, it will be converted to
            ``dtype=np.float32`` and if a sparse matrix is provided
            to a sparse ``csr_matrix``.

        Returns
        -------
        leverages: array of shape = [n_samples]
                   The objects distances to center of the training set.
        """
        # Check is fit had been called
        check_is_fitted(self, ['inverse_influence_matrix'])
        # Check that X have correct shape
        X = check_array(X)
        leverages = self.__find_leverages(X, self.inverse_influence_matrix)
        return leverages

    def predict(self, X):
        """Predict inside or outside AD for X.

        Parameters
        ----------
        X : array-like or sparse matrix, shape (n_samples, n_features)
            The input samples. Internally, it will be converted to
            ``dtype=np.float32`` and if a sparse matrix is provided
            to a sparse ``csr_matrix``.

        Returns
        -------
        ad : array of shape = [n_samples]
            Array contains True (reaction in AD) and False (reaction residing outside AD).
        """
        # Check is fit had been called
        check_is_fitted(self, ['inverse_influence_matrix'])
        # Check that X have correct shape
        X = check_array(X)
        if self.warning_leverage == 'auto':
            ad = self.__find_leverages(X, self.inverse_influence_matrix) <=  self.threshold_value
            return ad
        elif self.warning_leverage == 'cv':
            ad = self.__find_leverages(X, self.inverse_influence_matrix) <= self.threshold_value['z']
            return ad


__all__ = ['Leverage']
