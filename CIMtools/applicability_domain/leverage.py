# -*- coding: utf-8 -*-
#
#  Copyright 2019 Assima Rakhimbekova <asima.astana@outlook.com>
#  This file is part of CIMtools.
#
#  CIMtools is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, see <https://www.gnu.org/licenses/>.
#
from numpy import array, column_stack, eye, linalg, ones
from sklearn.base import BaseEstimator
from sklearn.utils.validation import check_array, check_is_fitted


class Leverage(BaseEstimator):
    """ Distance-based method
    The model space can be represented by a two-dimensional matrix comprising n chemicals (rows) and
    k variables (columns), called the descriptor matrix (X). The leverage of a chemical provides a measure of the
    distance of the chemical from the centroid of X. Chemicals close to the centroid are less influential in model
    building than are extreme points. The leverages of all chemicals in the data set are generated by manipulating X
    according to Equation 1, to give the so-called Influence Matrix or Hat Matrix (H).

    H = X(XTX)–1 XT (Equation 1)

    where X is the descriptor matrix, XT is the transpose of X, and (A)–1 is the inverse of matrix A, where A = (XTX).

    The leverages or hat values (hi) of the chemicals (i) in the descriptor space are the diagonal elements of H,
    and can be computed by Equation 2.

    hii = xiT(XTX)–1 xi (Equation 2)

    where xi is the descriptor row-vector of the query chemical.
    A “warning leverage” (h*) is generally (!) fixed at 3p/n, where n is the number of training chemicals, and p
    the number of model variables plus one.

    A “warning leverage” can be found on internal cross-validation.

    A chemical with high leverage in the training set greatly influences
    the regression line: the fitted regression line is forced near to the observed value and its residual
    (observed-predicted value) is small, so the chemical does not appear to be an outlier, even though it may actually
    be outside the AD. In contrast, if a chemical in the test set has a hat value greater than the warning leverage h*,
    this means that the prediction is the result of substantial extrapolation and therefore may not be reliable.
    """
    def __init__(self):
        pass

    def fit(self, X, y=None):
        """ Learning is to build an inverse matrix

        Parameters
        ----------
        X : array-like or sparse matrix, shape (n_samples, n_features)
            The input samples. Use ``dtype=np.float32`` for maximum
            efficiency.
        y : array-like, shape = [n_samples] or [n_samples, n_outputs]
            The target values (real numbers in regression).
        Returns
        -------
        self : object
            Returns self.
        """
        X = check_array(X)
        if y is not None:
            y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)
        X = column_stack(((ones(X.shape[0])), X))
        influence_matrix = X.T.dot(X) + eye(X.shape[1]).dot(1e-8)
        self.inverse_influence_matrix = linalg.inv(influence_matrix)
        return self

    def predict_proba(self, X):
        """

        Parameters
        ----------
        X : array-like or sparse matrix, shape (n_samples, n_features)
               The input samples. Internally, it will be converted to
               ``dtype=np.float32`` and if a sparse matrix is provided
               to a sparse ``csr_matrix``.

        Returns
        -------

        """
        check_is_fitted(self, ['inverse_influence_matrix'])
        X = check_array(X)
        X = column_stack(((ones(X.shape[0])), X))
        return array([X[i, :].dot(self.inverse_influence_matrix).dot(X[i, :]) for i in range(X.shape[0])])


__all__ = ['Leverage']
